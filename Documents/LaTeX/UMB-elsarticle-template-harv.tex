%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is based on part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.  Contact Elsevier for this file.
%%

%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
%% SP 2008/03/01 
%%
%% $Id: elsarticle-template-harv.tex 4 2009-10-24 08:22:58Z rishi $
%%
%% This template is based on the 'elsarticle-template-harv.tex', but has been modified for specific use with submissions to the journal Ultrasound in Medicine and Biology, June 2010, KJH
%

% Use this set of document class options for submission
\documentclass[preprint,5p]{elsarticle}

% Use this set of document class options to obtain an approximate 2 column view, note that this is primarily intended to allow authors to determine line breaks for long equations.  It is NOT meant to identically reproduce how the article would look in print.
%\documentclass[3p,twocolumn,authoryear,12pt]{elsarticle}


%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
 \usepackage{lineno}
 
 %% The multirow package adds the ability to do multirow and 
 %% multicolumn spanning in LaTeX.  This package is used 
 %% as an example for this template in the tables section.
 \usepackage{multirow}

\journal{Ultrasound in Medicine and Biology}

\begin{document}

\begin{frontmatter}

%% Title

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{A template for \LaTeX ~submissions to the journal Ultrasound in Medicine and Biology}


%% Authors and addresses/affiliations

%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes; note the corresponding author can be any of the authors, but one author must be designated; here the third author has been arbitrarily designated as the corresponding author as an example.
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:

%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\author[Affil1]{First Author}
\author[Affil2]{Second Author}
\author[Affil1]{Third/Corresponding Author \corref{cor1}}
\address[Affil1]{Affiliation address 1}
\address[Affil2]{Affiliation address 2}
% Replace capitalized text with the appropriate information (use standard capitalization rules for your text, not all capitals.
\cortext[cor1]{Corresponding Author: AUTHOR'S NAME, TYPE AUTHOR'S POSTAL ADDRESS; Email, TYPE CORRESPONDING AUTHOR'S EMAIL ADDRESS; Phone, TYPE CORRESPONDING AUTHOR'S PHONE NUMBER}


\begin{abstract}
%% Text of abstract
Type your abstract here  
\end{abstract}


\begin{keyword}
%% keywords here, in the form: keyword \sep keyword.  You may use no more than 10 keywords.
Keyword 1 \sep Keyword 2 \sep Keyword 3
\end{keyword}

\end{frontmatter}

%% Do not remove the page break here.
\pagebreak

\linenumbers

%% MAIN TEXT INSTRUCTIONS

%% For all sections, subsections, and subsubsections, use the '*' to remove numbering, as demonstrated below.

%% Commands for figures and tables should not be included in the main body of the submitted version of this file (e.g. the figure and tabular environments).  Figure captions should be listed in this file, as shown below.  Tables and Table captions should be listed as a separate section at the end of this file, as shown below.  Many authors may wish to include figures and tables within the main text of their document will preparing their manuscript.  This may be done, however please comment out any of the lines prior to submission.

%% Because the Elsevier editorial process does not allow for the figure and tabular environments in the submitted document, you will be unable to use autonumbering (i.e. \label and \ref) for figures and tables. 

%%  If long equations are used in the document, authors should use a two column format to make sure that the equations will break at approximately the right places.  To do this, replace the class option 'review' with the following two class options '3p' and 'twocolumn'.  Keep in mind that the column width produced in '3p' is slightly narrower than the final printer version.  After inserting the appropriate line breaks in your equation, change the '3p' option back to 'review'.

%% For citations, use the commands \citep and \citet

%% BEGIN MAIN TEXT

%%%%%%%%%%% INTRODUCTION
\section*{INTRODUCTION}
\label{intro}
Ultrasound devices have become increasingly affordable and portable, encouraging applications such as point-of-care ultrasound, novice usage, and data collection for machine learning. However, ultrasound is susceptible to unique artifacts that increase the difficult of interpretation and processing of images. One artifact is an acoustic shadow, which occurs when an ultrasound wave propagates from the transducer to a boundary of two materials with high impedance differences. The wave is almost completely reflected and beyond the boundary is a continuous dark region and a total loss of anatomical features. Acoustic shadows occur in air-tissue, tissue-bone, and tissue-lesion interfaces. Shadows can aid interpretation, such as identifying the presence of a gall stones or spinal level. However, shadows, such as from poor transducer contact, can lead to misinterpretation of anatomy, particularly by novice users and automated processing algorithms. Thus, the identification of shadows is an important preprocessing step in many applications.

Several methods have been used in literature to detect shadows. Geometric techniques model the path of an ultrasound signal for an expected image along the scanline using a random walk. Regions are then flagged as a shadow if a pixel is below a confidence threshold. However, geometric techniques require knowledge of the ultrasound transducer properties to assign weights to a random walk, such as the focal length, radius of curvature, and thickness. The technique would be cumbersome to implement across different ultrasound machines, especially if the source of the ultrasound images are unknown. This reduces the data available for machine learning applications and requires accurate transducer parameter labels for each image.

Pixel intensity methods ignore the properties of the transducer an analyze only the graphical properties of the image. Shadows have been detected on brain images by analyzing the entropy along a scanline to flag pixels of sudden low intensity as a potential shadow. The technique achieved a comparable Dice similarity coefficient as geometric methods but require specific thresholding, window sizing, filtering, and image mask parameterization for different anatomy. This method would be unfeasible in a clinical setting, particularly for novice users or point-of-care applications, as parameterization requires image processing expertise.

Machine learning methods have gained significant interest in medical imaging analysis although to our knowledge, no machine learning method has demonstrated capability of detecting shadows from multiple anatomy. Deep learning methods have been demonstrated to identify features in a common image set that contains a shadow, such as neuroanatomical regions in cranial scan or spinal levels in a posterior scan. Although machine learning has the potential of providing automated feature recognition in multiple applications, a large data set is required for an algorithm to recognize certain features. Ultrasound imaging is highly variable due to unique artifacts, operator technique, and equipment. In addition, shadows occur in various anatomy. Previous techniques focus on a single anatomical region and training data was from a consistent imaging scenario. However, it is difficult to construct a training data set with the generality required to recognize shadows in different scenarios usable for a variety of ultrasound applications.

We present a method utilizing radiofrequency (RF) or brightness-mode (B-mode) data that can detect shadows from multiple anatomy or transducers with minimum user configuration required. 

%%%%%%%%%%% MATERIALS AND METHODS
\section*{METHODS}
\label{MaM}
     
\subsection*{Data Collection}
Ultrasound RF and B-mode data was acquired by scanning 37 adult participants with informed written consent, approved by the University of British Columbia Research Ethics Board (Study ID: H18-01199). The scans included a forearm scan near the distal end of the pronator quadratus, an elbow scan near the cubital fossa, and a rib scan on the anterior surface of right ribs 11-12. Each scan was taken with both a curvilinear (C5-2/60, Ultrasonix, Canada) and linear (L14-5/38, Ultrasonix, Canada) transducer. Different transducer settings were used for each anatomical region and transducer, summarized in Table 1. The experiment was designed to generate a dataset from various imaging scenarios to validate the versatility of the shadow detection method.


\begin{table}[]
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		\textbf{}                                                                                              & \textbf{Anatomy} & \textbf{Frequency} & \textbf{Depth} & \textbf{Gain} \\ \hline
		\multirow{3}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Linear\\ Transducer\\ (L14-5/38)\end{tabular}}}     & Forearm          & 11.0MHz            & 5.0cm          & 50\%          \\ \cline{2-5} 
		& Elbow            & 11.0MHz            & 5.0cm          & 40\%          \\ \cline{2-5} 
		& Ribcage          & 5.0MHz             & 10.0cm         & 30\%          \\ \hline
		\multirow{3}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Curvilinear\\ Transducer\\ (C5-2/60)\end{tabular}}} & Forearm          & 4.0MHz             & 5.0cm          & 50\%          \\ \cline{2-5} 
		& Elbow            & 4.0MHz             & 5.0cm          & 40\%          \\ \cline{2-5} 
		& Ribcage          & 3.3MHz             & 10.0cm         & 30\%          \\ \hline
	\end{tabular}
\end{table}


\subsection*{Radiofrequency Speckle Analysis}      
To detect shadows, patches of speckle was analyzed on the RF signal. Speckle occurs due to multiplicative scattering of acoustic waves in a material, resulting in a granular patch on the image. B-mode data commonly attempts to remove speckle, but speckle contains information of the acoustic interactions in tissue. Speckle can then characterize different regions, such as a region of tissue or a region of signal loss in a shadow.

One of the first models for speckle is with a one-parameter Rayleigh distribution to model the probability density of a random walk. The Rayleigh is capable for modeling fully developed speckle, which does not occur when there is limited scattering. More generalized models have been applied such as the Rician, Homodyned K, and Nakagami distributions to characterize general speckle. Speckle has been leveraged to analyze features such as classifying tumorigenicity of breast lesions or levels of liver fibrosis. Shadow detection presents a simpler problem than comparing regions of similar tissue as a shadow and non-shadow region contain significantly different speckle patterns. Thus, the Nakagami distribution expressed in Eq. 1 was chosen to model speckle. The Nakagami distribution provides greater generality than the Rayleigh distribution while being more computationally efficient than the Rician or Homodyned K distributions.

To detect shadows, the raw RF data was first processed by computing the echo envelope of each scanline with a Hilbert transform. An absolute logarithmic scale of the echo envelope was taken to generate an "RF Image", which is visually similar to B-mode without filtering to remove artifacts. Next,

\begin{figure}
	\includegraphics[scale=0.5]{fig2.pdf}
\end{figure}

\begin{figure}
	\includegraphics[scale=0.55]{fig1.pdf}
\end{figure}
%%%%%%%%%%% Results
\section*{Results}
\label{Results}

\begin{table}[]
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{}                                                                                 &         & \textbf{RF Speckle} & \textbf{Entropy Thresholding} \\ \hline
		\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Linear\\ Transducer\\ (L14-5/38)\end{tabular}} & Forearm & x                   & x                             \\ \cline{2-4} 
		& Elbow   & x                   & x                             \\ \cline{2-4} 
		& Ribcage & x                   & x                             \\ \hline
		\multirow{3}{*}{Curvilinear Transducer}                                                   & Forearm & x                   & x                             \\ \cline{2-4} 
		& Elbow   & x                   & x                             \\ \cline{2-4} 
		& Ribcage & x                   & x                             \\ \hline
	\end{tabular}
\end{table}

%%%%%%%%%%% DISCUSSION
\section*{Discussion}
\label{Discuss}
The quick brown fox jumps over the lazy dog.

%%%%%%%%%%% Conclusions
\section*{Conclusions}
\label{Conclusions}
The quick brown fox jumps over the lazy dog.

        
%%%%%%%%%%% ACKNOWLEDGEMENTS
\section*{Acknowledgements}
\label{Ack}
Type in any acknowledgements here.  If there are no acknowledgments, please delete or comment out this section.



%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section*{}
%% \label{}


%%%%%%%%%%% REFERENCES
%% REFERENCE FORMATTING INSTRUCTIONS

%% All bibliography information should be included using a 'thebibliography' environment.  Most authors will find it easiest to create a .bbl file using the commands \bibliographystyle{} and \bibliography{} and then copy and paste the contents of the .bbl file into the .tex file below, but before the figure captions section.  Examples for using the \bibliographystyle and \bibliography commands are listed below.  

%% Do not remove the page break here.
\pagebreak

%% References with bibTeX database, use this to create a .bbl file
%\bibliographystyle{UMB-elsarticle-harvbib}
%\bibliography{FILENAME_OF_YOUR_BIBTEX_DATABASE}

%% References copied and pasted from the .bbl file.  Copy and paste over the following two lines.  When using a bibTeX database to create a .bbl file, comment out the following two lines.
\begin{thebibliography}{00}
\end{thebibliography}

%%%%%%%%%%% FIGURE CAPTIONS

%% Include only the figure captions here (not the figures).  Figures are uploaded separately in the online Elsevier Editorial Submission process.

%% Do not remove the page break here.
\pagebreak

\section*{Figure Captions}

\begin{description}
\item[Figure 1:]  TYPE THE CAPTION FOR FIGURE ONE HERE.
\item[Figure 2:]  TYPE THE CAPTION FOR FIGURE TWO HERE.
\item[Figure 3:]  TYPE THE CAPTION FOR FIGURE ONE HERE.  CONTINUE THIS LIST FOR ALL OTHER CAPTIONS
\end{description}

%%%%%%%%%%% TABLES AND TABLE CAPTIONS

%% Both tables and table captions should be included below.  Captions should appear above the table, as shown below. If users want to use multirow.sty, array.sty, etc., to fine control/enhance the tables, they are welcome to load any package of their choice and the elsearticle.cls should work in combination with all loaded packages.  For problems with loaded packages please contact: elsarticle@river-valley.com (the developers of the elsarticle document class) or support@elsevier.com (Elsevier customer support).

%% Since the tabular format is often difficult to work with for complex tables, authors may also choose to create their tables with another program.  Each table and it's corresponding caption should then be saved as a pdf.  Each pdf should then be uploaded separately during the online submission process.  If doing so, all of the text below concerning tables and table captions should be commented out.

%% If no tables are part of the manuscript, comment out or delete this entire section.

%% Do not remove the page break here.
\pagebreak

\section*{Tables}

\begin{description}
\item[Table 1:]  TYPE THE CAPTION FOR TABLE ONE HERE. \\

\begin{tabular}{|c||ccc||r|}
	\hline
\textbf{\em k}  &  $x_1^k$    &   $x_2^k$  & $x_3^k$ & remarks    \\
	\hline \hline
0   & -0.30000000 & 0.60000000 & ~0.70000000 & $x^0$ \\
1   & ~0.47102965 & 0.04883157 & -0.53345964 &   \\
2   & ~0.49988691 & 0.00228830 & -0.52246185 &   \\
3   & ~0.49999976 & 0.00005380 & -0.52365600 & $\epsilon<\delta$ \\
4   & ~0.50000000 & 0.00000307 & -0.52359743 & ($\forall n>N$) \\
	\hline
7   & ~0.50000000 & 0.00000000 & -0.52359878 & $\epsilon\ll\zeta$ \\
	\hline
\end{tabular} \\


\item[Table 2:]  TYPE THE CAPTION FOR TABLE TWO HERE. 

\begin{tabular}{|l|l|l|} \hline
\multicolumn{3}{|c|}{Heading} \\ \hline
\multirow{3}{*}{Row 1} & subtopic 1 & Result A \\
& subtopic 2 & Result B \\
& subtopic 3 & Result C \\ \hline
\multirow{4}{*}{Row 2} & subtopic 1 & Result D \\ 
& subtopic 2 & Result E \\
& subtopic 3 & Result F \\ 
& subtopic 4 & Result G \\ \hline
\end{tabular} \\

\end{description}

%%%%%%%%%%% VIDEO CAPTIONS

%% If submitting video's as a supplement to the manuscript, include only the video captions here (not the figures).  Videos are uploaded separately in the online Elsevier Editorial Submission process.  If videos are not included, comment out this section.

%% Do not remove the page break here.
\pagebreak

\section*{Video Captions}

\begin{description}
\item[Figure 1:]  TYPE THE CAPTION FOR VIDEO ONE HERE.
\item[Figure 2:]  TYPE THE CAPTION FOR VIDEO TWO HERE.
\item[Figure 3:]  TYPE THE CAPTION FOR VIDEO ONE HERE.  CONTINUE THIS LIST FOR ALL OTHER CAPTIONS
\end{description}



\end{document}
